from fastapi import FastAPI
import joblib
import gdown
import numpy as np
import json
import os
from pydantic import BaseModel
import uvicorn

# === Configuration ===
MODEL_ID = os.environ.get("BETSMART_DRIVE_MODEL_ID", "1FBM4lYhm9pvEmlL4vmJV0YMKl-rIIXaJ")
MODEL_PATH = "/tmp/bet_predict_model.pkl"  # Utilise /tmp sur Render
MAPPING_PATH = "team_league_mapping.json"

app = FastAPI(title="Betsmart Prediction API", version="1.0")

# === Cache pour le mapping uniquement (l√©ger)
mapping_cache = None


# === Mod√®le d‚Äôentr√©e API ===
class MatchInput(BaseModel):
    team1: str
    team2: str
    league: str
    odd1: float
    oddx: float
    odd2: float


# === T√©l√©chargement du mod√®le depuis Google Drive ===
def download_model():
    """T√©l√©charge le mod√®le depuis Google Drive uniquement s'il n'existe pas d√©j√†."""
    if not os.path.exists(MODEL_PATH):
        print("üì• T√©l√©chargement du mod√®le depuis Google Drive...")
        url = f"https://drive.google.com/uc?id={MODEL_ID}"
        gdown.download(url, MODEL_PATH, quiet=False)
        print("‚úÖ Mod√®le t√©l√©charg√© avec succ√®s.")


# === Chargement du mapping JSON (l√©ger, gard√© en m√©moire) ===
def load_mapping():
    """Charge le mapping une seule fois (l√©ger)."""
    global mapping_cache
    if mapping_cache is None:
        with open(MAPPING_PATH, "r") as f:
            mapping_cache = json.load(f)
        print("‚úÖ Mapping charg√© avec succ√®s.")


# === Endpoint /predict ===
@app.post("/predict")
async def predict_match(data: MatchInput):
    """
    Endpoint principal ‚Äî calcule la pr√©diction pour un match.
    Le mod√®le est charg√© temporairement pour √©viter les crashs m√©moire.
    """
    try:
        # Charger le mapping (l√©ger)
        load_mapping()

        # V√©rifier les identifiants d'√©quipes et de ligue
        league_id = mapping_cache["LEAGUE"].get(data.league)
        team1_id = mapping_cache["TEAM1"].get(data.team1)
        team2_id = mapping_cache["TEAM2"].get(data.team2)

        if None in (league_id, team1_id, team2_id):
            return {"status": "error", "message": "Nom d'√©quipe ou ligue introuvable"}

        # T√©l√©charger et charger le mod√®le dans /tmp
        download_model()
        model = joblib.load(MODEL_PATH)
        print("‚úÖ Mod√®le charg√© temporairement pour pr√©diction.")

        # Effectuer la pr√©diction
        X_new = np.array([[league_id, team1_id, team2_id, data.odd1, data.oddx, data.odd2]])
        proba = model.predict_proba(X_new)[0]
        classes = model.classes_

        # Supprimer le mod√®le imm√©diatement pour lib√©rer la m√©moire
        del model
        if os.path.exists(MODEL_PATH):
            os.remove(MODEL_PATH)
            print("üßπ Mod√®le supprim√© de /tmp pour lib√©rer la m√©moire.")

        # Construire la r√©ponse
        results = dict(zip(classes, [float(p) for p in proba]))
        best = max(results, key=results.get)

        return {
            "status": "ok",
            "prediction": best,
            "probabilities": results
        }

    except Exception as e:
        return {"status": "error", "message": str(e)}


# === Endpoint racine (test de vie) ===
@app.get("/")
def root():
    """Simple test pour v√©rifier que l'API fonctionne."""
    return {"message": "‚úÖ Betsmart Prediction API is running!"}


# === Lancer localement (d√©veloppement) ===
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
